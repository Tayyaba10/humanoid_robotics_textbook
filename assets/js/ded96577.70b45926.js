"use strict";(globalThis.webpackChunkhumanoid_robotics_textbook=globalThis.webpackChunkhumanoid_robotics_textbook||[]).push([[914],{2277:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>c,contentTitle:()=>s,default:()=>d,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"ai-robot-brain/path-planning-reinforcement-learning","title":"Path Planning and Reinforcement Learning","description":"Explore path planning algorithms and reinforcement learning techniques for humanoid robots in NVIDIA Isaac Sim.","source":"@site/docs/03-ai-robot-brain/03-path-planning-reinforcement-learning.mdx","sourceDirName":"03-ai-robot-brain","slug":"/ai-robot-brain/path-planning-reinforcement-learning","permalink":"/humanoid_robotics_textbook/ai-robot-brain/path-planning-reinforcement-learning","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Path Planning and Reinforcement Learning","description":"Explore path planning algorithms and reinforcement learning techniques for humanoid robots in NVIDIA Isaac Sim.","slug":"/ai-robot-brain/path-planning-reinforcement-learning","keywords":["Path Planning","Reinforcement Learning","NVIDIA Isaac Sim","Robotics AI","Humanoid Robotics"]},"sidebar":"tutorialSidebar","previous":{"title":"Isaac ROS & Visual SLAM (VSLAM)","permalink":"/humanoid_robotics_textbook/ai-robot-brain/chapter-3.2-isaac-ros-vslam"},"next":{"title":"3. Perception & Sensing","permalink":"/humanoid_robotics_textbook/perception-sensing"}}');var a=i(4848),r=i(8453);const o={title:"Path Planning and Reinforcement Learning",description:"Explore path planning algorithms and reinforcement learning techniques for humanoid robots in NVIDIA Isaac Sim.",slug:"/ai-robot-brain/path-planning-reinforcement-learning",keywords:["Path Planning","Reinforcement Learning","NVIDIA Isaac Sim","Robotics AI","Humanoid Robotics"]},s="Path Planning and Reinforcement Learning",c={},l=[];function h(n){const e={h1:"h1",header:"header",li:"li",p:"p",ul:"ul",...(0,r.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"path-planning-and-reinforcement-learning",children:"Path Planning and Reinforcement Learning"})}),"\n",(0,a.jsx)(e.p,{children:"This chapter delves into path planning algorithms and reinforcement learning (RL) techniques for humanoid robots within the NVIDIA Isaac Sim environment. We will cover:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Fundamentals of Path Planning"}),"\n",(0,a.jsx)(e.li,{children:"Reinforcement Learning for Robotics"}),"\n",(0,a.jsx)(e.li,{children:"Integrating Path Planning and RL in Isaac Sim"}),"\n"]}),"\n",(0,a.jsx)("h2",{children:"Introduction to Path Planning"}),"\n",(0,a.jsx)("h2",{children:"Reinforcement Learning for Robotics"}),"\n",(0,a.jsx)("h2",{children:"Integration in Isaac Sim"}),"\n",(0,a.jsx)("h2",{children:"Exercises"}),"\n",(0,a.jsx)("h3",{children:"Troubleshooting"}),"\n",(0,a.jsx)("h2",{children:"References"})]})}function d(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(h,{...n})}):h(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>s});var t=i(6540);const a={},r=t.createContext(a);function o(n){const e=t.useContext(r);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),t.createElement(r.Provider,{value:e},n.children)}}}]);