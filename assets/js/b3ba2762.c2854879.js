"use strict";(globalThis.webpackChunkhumanoid_robotics_textbook=globalThis.webpackChunkhumanoid_robotics_textbook||[]).push([[276],{1470:(e,t,n)=>{n.d(t,{A:()=>j});var i=n(6540),a=n(4164),o=n(7559),s=n(3104),r=n(6347),l=n(205),d=n(7485),c=n(1682),u=n(679);function h(e){return i.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function p(e){const{values:t,children:n}=e;return(0,i.useMemo)(()=>{const e=t??function(e){return h(e).map(({props:{value:e,label:t,attributes:n,default:i}})=>({value:e,label:t,attributes:n,default:i}))}(n);return function(e){const t=(0,c.XI)(e,(e,t)=>e.value===t.value);if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[t,n])}function m({value:e,tabValues:t}){return t.some(t=>t.value===e)}function b({queryString:e=!1,groupId:t}){const n=(0,r.W6)(),a=function({queryString:e=!1,groupId:t}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:e,groupId:t});return[(0,d.aZ)(a),(0,i.useCallback)(e=>{if(!a)return;const t=new URLSearchParams(n.location.search);t.set(a,e),n.replace({...n.location,search:t.toString()})},[a,n])]}function f(e){const{defaultValue:t,queryString:n=!1,groupId:a}=e,o=p(e),[s,r]=(0,i.useState)(()=>function({defaultValue:e,tabValues:t}){if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${t.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const n=t.find(e=>e.default)??t[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:o})),[d,c]=b({queryString:n,groupId:a}),[h,f]=function({groupId:e}){const t=function(e){return e?`docusaurus.tab.${e}`:null}(e),[n,a]=(0,u.Dv)(t);return[n,(0,i.useCallback)(e=>{t&&a.set(e)},[t,a])]}({groupId:a}),g=(()=>{const e=d??h;return m({value:e,tabValues:o})?e:null})();(0,l.A)(()=>{g&&r(g)},[g]);return{selectedValue:s,selectValue:(0,i.useCallback)(e=>{if(!m({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);r(e),c(e),f(e)},[c,f,o]),tabValues:o}}var g=n(2303);const y={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var v=n(4848);function w({className:e,block:t,selectedValue:n,selectValue:i,tabValues:o}){const r=[],{blockElementScrollPositionUntilNextRender:l}=(0,s.a_)(),d=e=>{const t=e.currentTarget,a=r.indexOf(t),s=o[a].value;s!==n&&(l(t),i(s))},c=e=>{let t=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const n=r.indexOf(e.currentTarget)+1;t=r[n]??r[0];break}case"ArrowLeft":{const n=r.indexOf(e.currentTarget)-1;t=r[n]??r[r.length-1];break}}t?.focus()};return(0,v.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.A)("tabs",{"tabs--block":t},e),children:o.map(({value:e,label:t,attributes:i})=>(0,v.jsx)("li",{role:"tab",tabIndex:n===e?0:-1,"aria-selected":n===e,ref:e=>{r.push(e)},onKeyDown:c,onClick:d,...i,className:(0,a.A)("tabs__item",y.tabItem,i?.className,{"tabs__item--active":n===e}),children:t??e},e))})}function x({lazy:e,children:t,selectedValue:n}){const o=(Array.isArray(t)?t:[t]).filter(Boolean);if(e){const e=o.find(e=>e.props.value===n);return e?(0,i.cloneElement)(e,{className:(0,a.A)("margin-top--md",e.props.className)}):null}return(0,v.jsx)("div",{className:"margin-top--md",children:o.map((e,t)=>(0,i.cloneElement)(e,{key:t,hidden:e.props.value!==n}))})}function _(e){const t=f(e);return(0,v.jsxs)("div",{className:(0,a.A)(o.G.tabs.container,"tabs-container",y.tabList),children:[(0,v.jsx)(w,{...t,...e}),(0,v.jsx)(x,{...t,...e})]})}function j(e){const t=(0,g.A)();return(0,v.jsx)(_,{...e,children:h(e.children)},String(t))}},1555:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>h,contentTitle:()=>u,default:()=>b,frontMatter:()=>c,metadata:()=>i,toc:()=>p});const i=JSON.parse('{"id":"world-modeling","title":"4. World Modeling & State Estimation","description":"How robots build and maintain a model of the world and their place within it.","source":"@site/docs/04-world-modeling.mdx","sourceDirName":".","slug":"/world-modeling","permalink":"/humanoid_robotics_textbook/world-modeling","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"world-modeling","title":"4. World Modeling & State Estimation","description":"How robots build and maintain a model of the world and their place within it.","sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Capstone - Autonomous Humanoid Robot","permalink":"/humanoid_robotics_textbook/vla/capstone-autonomous-humanoid"},"next":{"title":"5. Control Architectures for Locomotion","permalink":"/humanoid_robotics_textbook/control-locomotion"}}');var a=n(4848),o=n(8453),s=n(418),r=n(3457),l=n(1470),d=n(9365);const c={id:"world-modeling",title:"4. World Modeling & State Estimation",description:"How robots build and maintain a model of the world and their place within it.",sidebar_position:4},u=void 0,h={},p=[{value:"The Internal Universe: Models and Beliefs",id:"the-internal-universe-models-and-beliefs",level:2},{value:"The Grand Challenge: SLAM",id:"the-grand-challenge-slam",level:3},{value:"How to Represent the World?",id:"how-to-represent-the-world",level:3},{value:"Occupancy Grids",id:"occupancy-grids",level:4},{value:"Point Clouds",id:"point-clouds",level:4},{value:"Semantic Maps",id:"semantic-maps",level:4},{value:"Code Example: Intuition Behind State Estimation",id:"code-example-intuition-behind-state-estimation",level:3}];function m(e){const t={code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.h2,{id:"the-internal-universe-models-and-beliefs",children:"The Internal Universe: Models and Beliefs"}),"\n",(0,a.jsxs)(t.p,{children:["In the last chapter, we saw how a robot gathers snapshots of the world through its sensors. But how does it connect these snapshots over time to build a persistent, internal understanding of the world? And how does it track its own position within that world? This is the domain of ",(0,a.jsx)(t.strong,{children:"world modeling"})," and ",(0,a.jsx)(t.strong,{children:"state estimation"}),"."]}),"\n",(0,a.jsxs)(t.p,{children:["The core challenge is that a robot can never know its true ",(0,a.jsx)(t.strong,{children:"state"})," (a collection of variables like position, orientation, and velocity) with perfect certainty. All sensor measurements are noisy, and all actions are imprecise. Therefore, the robot must ",(0,a.jsx)(t.em,{children:"estimate"})," its state."]}),"\n",(0,a.jsxs)(t.p,{children:["This estimate is not a single value, but a ",(0,a.jsx)(t.strong,{children:"belief"}),", which is a probability distribution over all possible states. The goal of state estimation is to keep this belief as sharp and accurate as possible, meaning the robot is highly confident about its state."]}),"\n",(0,a.jsx)(t.h3,{id:"the-grand-challenge-slam",children:"The Grand Challenge: SLAM"}),"\n",(0,a.jsx)(t.p,{children:"For a robot operating in a new environment, this leads to a classic chicken-and-egg problem:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["To know where you are (",(0,a.jsx)(t.strong,{children:"Localization"}),"), you need an accurate map."]}),"\n",(0,a.jsxs)(t.li,{children:["To build an accurate map (",(0,a.jsx)(t.strong,{children:"Mapping"}),"), you need to know where you are."]}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Simultaneous Localization and Mapping (SLAM)"})," is the set of techniques that solves both problems at the same time. As the robot moves, it builds a map of the environment while simultaneously using that map to figure out its location."]}),"\n",(0,a.jsx)(t.p,{children:"The core SLAM loop is a powerful cycle of prediction and correction."}),"\n",(0,a.jsx)(s.A,{chart:'\ngraph TD\n  A(Start) --\x3e B{Move Robot};\n  B --\x3e C{Predict New Pose};\n  C --\x3e D{Sense Environment};\n  D --\x3e E{Find Landmark Matches};\n  E --\x3e F{Update Pose & Map};\n  F --\x3e B;\n  subgraph "Prediction"\n      B; C;\n  end\n  subgraph "Correction"\n      D; E; F;\n  end\n  style A fill:#f9f9f9,stroke:#333,stroke-width:2px\n  style B fill:#bde0fe\n  style F fill:#bde0fe\n'}),"\n",(0,a.jsxs)(t.ol,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Move & Predict:"})," The robot moves, and based on its motor commands (proprioception), it predicts its new state. Its uncertainty grows during this step."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Sense & Match:"})," The robot observes the environment with its sensors (e.g., LiDAR or cameras) and finds landmarks that it has seen before."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Update:"})," By matching the newly observed landmarks to the ones in its map, the robot can correct its predicted state, reducing its uncertainty. It then uses this corrected state to refine and extend the map."]}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:["A crucial part of this process is ",(0,a.jsx)(t.strong,{children:"loop closure"}),". When a robot recognizes a place it has been before after a long journey, it can drastically reduce the accumulated error in its trajectory, snapping the map into a much more consistent state."]}),"\n",(0,a.jsx)(t.h3,{id:"how-to-represent-the-world",children:"How to Represent the World?"}),"\n",(0,a.jsx)(t.p,{children:'A "map" can take many forms, depending on the robot\'s task.'}),"\n",(0,a.jsx)(t.h4,{id:"occupancy-grids",children:"Occupancy Grids"}),"\n",(0,a.jsx)(t.p,{children:"This is one of the most common representations for navigation. The world is divided into a 2D or 3D grid. Each cell in the grid stores a probability value representing the belief that the cell is occupied by an obstacle. This is simple, effective, and excellent for finding clear paths."}),"\n",(0,a.jsx)(t.h4,{id:"point-clouds",children:"Point Clouds"}),"\n",(0,a.jsx)(t.p,{children:"A point cloud is a direct, geometric representation of the world, typically generated by a LiDAR or a depth camera. It's a massive collection of 3D points. While very detailed, point clouds are computationally intensive to process and store. They are often used as an intermediate representation to build other map types."}),"\n",(0,a.jsx)(t.h4,{id:"semantic-maps",children:"Semantic Maps"}),"\n",(0,a.jsxs)(t.p,{children:['A semantic map is a higher-level, more "human-like" representation of the world. Instead of just storing geometry, it stores objects and their properties (their "semantics"). The map might contain not just a cluster of points, but an entity labeled ',(0,a.jsx)(t.code,{children:"chair"}),' with a specific pose and size. This allows the robot to reason about its environment in a much more intelligent way (e.g., "Find me a chair to sit on").']}),"\n",(0,a.jsx)(t.h3,{id:"code-example-intuition-behind-state-estimation",children:"Code Example: Intuition Behind State Estimation"}),"\n",(0,a.jsxs)(t.p,{children:["Let's illustrate the core idea of state estimation (prediction and update) with a simple 1D example. Imagine a robot moving along a line. It thinks it's at position ",(0,a.jsx)(t.code,{children:"10.0"}),", but its sensors are noisy."]}),"\n",(0,a.jsx)(l.A,{children:(0,a.jsx)(d.A,{value:"python",label:"Python",children:(0,a.jsx)(r.A,{language:"python",children:(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'import numpy as np\n\n# Our belief about the robot\'s state (position and velocity)\n# We believe it\'s at position 10.0, stopped, but we are uncertain.\n# The covariance matrix expresses this uncertainty.\nestimated_pos = 10.0\nestimated_pos_uncertainty = 2.0  # High uncertainty\n\ndef predict(pos, uncertainty, movement_dist):\n    """\n    Predicts the next state based on movement.\n    Uncertainty increases because movement itself is not perfect.\n    """\n    predicted_pos = pos + movement_dist\n    predicted_uncertainty = uncertainty + 0.5 # Add motion uncertainty\n    print(f"PREDICT: Moved by {movement_dist}. Predicted position: {predicted_pos:.2f}, Uncertainty: {predicted_uncertainty:.2f}")\n    return predicted_pos, predicted_uncertainty\n\ndef update(predicted_pos, predicted_uncertainty, measurement, measurement_uncertainty):\n    """\n    Updates the belief by fusing the prediction with a new sensor measurement.\n    This is a simplified version of the Kalman Gain calculation.\n    """\n    # Calculate a weighted average. Trust the value with less uncertainty more.\n    kalman_gain = predicted_uncertainty / (predicted_uncertainty + measurement_uncertainty)\n    \n    new_pos = predicted_pos + kalman_gain * (measurement - predicted_pos)\n    new_uncertainty = (1 - kalman_gain) * predicted_uncertainty\n\n    print(f"UPDATE:  Got measurement {measurement:.2f}. Fusing prediction with measurement.")\n    print(f"         New Position: {new_pos:.2f}, New Uncertainty: {new_uncertainty:.2f}\\n")\n    return new_pos, new_uncertainty\n\n# --- Simulation Loop ---\n# 1. Initial State\nprint(f"START:   Initial Position: {estimated_pos:.2f}, Uncertainty: {estimated_pos_uncertainty:.2f}\\n")\n\n# 2. First Movement & Update\nestimated_pos, estimated_pos_uncertainty = predict(estimated_pos, estimated_pos_uncertainty, 5.0)\n# We get a sensor measurement that says we are at 16.0, but sensors are noisy.\nestimated_pos, estimated_pos_uncertainty = update(estimated_pos, estimated_pos_uncertainty, 16.0, 1.0)\n\n# 3. Second Movement & Update\nestimated_pos, estimated_pos_uncertainty = predict(estimated_pos, estimated_pos_uncertainty, 5.0)\n# We get another measurement that says we are at 20.5.\nestimated_pos, estimated_pos_uncertainty = update(estimated_pos, estimated_pos_uncertainty, 20.5, 1.0)\n\n# The final estimated position is a statistically robust fusion of all our\n# predictions and measurements, and our uncertainty has been reduced.\n'})})})})}),"\n",(0,a.jsx)(t.p,{children:"This simple example demonstrates the foundational logic of all state estimation. The robot continuously refines its belief by blending its own predictions with external measurements, allowing it to navigate the world with a confidence that no single sensor could provide."})]})}function b(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(m,{...e})}):m(e)}},9365:(e,t,n)=>{n.d(t,{A:()=>s});n(6540);var i=n(4164);const a={tabItem:"tabItem_Ymn6"};var o=n(4848);function s({children:e,hidden:t,className:n}){return(0,o.jsx)("div",{role:"tabpanel",className:(0,i.A)(a.tabItem,n),hidden:t,children:e})}}}]);