<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-perception-sensing" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">3. Perception &amp; Sensing | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://Tayyaba10.github.io/humanoid_robotics_textbook/perception-sensing/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="3. Perception &amp; Sensing | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="Exploring the sensors and algorithms that allow a robot to perceive its environment."><meta data-rh="true" property="og:description" content="Exploring the sensors and algorithms that allow a robot to perceive its environment."><link data-rh="true" rel="icon" href="/humanoid_robotics_textbook/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://Tayyaba10.github.io/humanoid_robotics_textbook/perception-sensing/"><link data-rh="true" rel="alternate" href="https://Tayyaba10.github.io/humanoid_robotics_textbook/perception-sensing/" hreflang="en"><link data-rh="true" rel="alternate" href="https://Tayyaba10.github.io/humanoid_robotics_textbook/perception-sensing/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"3. Perception & Sensing","item":"https://Tayyaba10.github.io/humanoid_robotics_textbook/perception-sensing"}]}</script><link rel="stylesheet" href="/humanoid_robotics_textbook/assets/css/styles.dc6cce39.css">
<script src="/humanoid_robotics_textbook/assets/js/runtime~main.fdbff0ec.js" defer="defer"></script>
<script src="/humanoid_robotics_textbook/assets/js/main.ac4e32f4.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/humanoid_robotics_textbook/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/humanoid_robotics_textbook/"><div class="navbar__logo"><img src="/humanoid_robotics_textbook/img/logo.svg" alt="Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/humanoid_robotics_textbook/img/logo.svg" alt="Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Humanoid Robotics Textbook</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/humanoid_robotics_textbook/introduction/">Chapters</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/Tayyaba10/humanoid_robotics_textbook" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/humanoid_robotics_textbook/introduction/"><span title="1. Introduction to Physical AI &amp; Humanoid Robotics" class="linkLabel_WmDU">1. Introduction to Physical AI &amp; Humanoid Robotics</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/humanoid_robotics_textbook/ros2/chapter-1.1-introduction-to-ros2/"><span title="ros2" class="categoryLinkLabel_W154">ros2</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/humanoid_robotics_textbook/humanoid-stack/"><span title="2. The Humanoid Stack: A Systems Overview" class="linkLabel_WmDU">2. The Humanoid Stack: A Systems Overview</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/humanoid_robotics_textbook/simulation/chapter-2.1-gazebo-basics/"><span title="simulation" class="categoryLinkLabel_W154">simulation</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/humanoid_robotics_textbook/ai-robot-brain/chapter-3.1-isaac-sim-overview/"><span title="AI-Robot Brain (NVIDIA Isaac)" class="categoryLinkLabel_W154">AI-Robot Brain (NVIDIA Isaac)</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/humanoid_robotics_textbook/perception-sensing/"><span title="3. Perception &amp; Sensing" class="linkLabel_WmDU">3. Perception &amp; Sensing</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/humanoid_robotics_textbook/vla/chapter-4.1-voice-command-integration/"><span title="Vision-Language-Action (VLA)" class="categoryLinkLabel_W154">Vision-Language-Action (VLA)</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/humanoid_robotics_textbook/world-modeling/"><span title="4. World Modeling &amp; State Estimation" class="linkLabel_WmDU">4. World Modeling &amp; State Estimation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/humanoid_robotics_textbook/control-locomotion/"><span title="5. Control Architectures for Locomotion" class="linkLabel_WmDU">5. Control Architectures for Locomotion</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/humanoid_robotics_textbook/manipulation/"><span title="6. Principles of Robotic Manipulation" class="linkLabel_WmDU">6. Principles of Robotic Manipulation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/humanoid_robotics_textbook/planning-decision-making/"><span title="7. Planning &amp; Decision-Making" class="linkLabel_WmDU">7. Planning &amp; Decision-Making</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/humanoid_robotics_textbook/embodied-learning/"><span title="8. Embodied Learning: RL and IL" class="linkLabel_WmDU">8. Embodied Learning: RL and IL</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/humanoid_robotics_textbook/foundation-models/"><span title="9. Foundation Models in Robotics" class="linkLabel_WmDU">9. Foundation Models in Robotics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/humanoid_robotics_textbook/simulation-sim-to-real/"><span title="10. Simulation &amp; Sim-to-Real" class="linkLabel_WmDU">10. Simulation &amp; Sim-to-Real</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/humanoid_robotics_textbook/hardware-software-codesign/"><span title="11. Hardware-Software Co-Design" class="linkLabel_WmDU">11. Hardware-Software Co-Design</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/humanoid_robotics_textbook/safety-failure-analysis/"><span title="12. Safety and Failure Analysis" class="linkLabel_WmDU">12. Safety and Failure Analysis</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/humanoid_robotics_textbook/future-of-humanoids/"><span title="13. The Road Ahead: Future of Humanoid Robotics" class="linkLabel_WmDU">13. The Road Ahead: Future of Humanoid Robotics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/humanoid_robotics_textbook/glossary/"><span title="Glossary" class="linkLabel_WmDU">Glossary</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/humanoid_robotics_textbook/"><span title="Quickstart Guide: Physical AI &amp; Humanoid Robotics Textbook Development" class="linkLabel_WmDU">Quickstart Guide: Physical AI &amp; Humanoid Robotics Textbook Development</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/humanoid_robotics_textbook/troubleshooting/"><span title="Troubleshooting" class="linkLabel_WmDU">Troubleshooting</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/humanoid_robotics_textbook/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">3. Perception &amp; Sensing</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>3. Perception &amp; Sensing</h1></header><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-goal-from-raw-data-to-understanding">The Goal: From Raw Data to Understanding<a href="#the-goal-from-raw-data-to-understanding" class="hash-link" aria-label="Direct link to The Goal: From Raw Data to Understanding" title="Direct link to The Goal: From Raw Data to Understanding" translate="no">​</a></h2>
<p>A humanoid robot&#x27;s ability to act meaningfully in the world is fundamentally limited by its ability to <em>perceive</em> the world. Perception is not merely about collecting data; it&#x27;s about transforming raw signals from a suite of sensors into a coherent, actionable understanding of the environment and the robot&#x27;s own state within it.</p>
<p>In this chapter, we explore the primary sensors that give a robot its &quot;senses&quot; and the foundational algorithms that begin the process of turning data into knowledge.</p>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="exteroceptive-sensors-seeing-the-world">Exteroceptive Sensors: Seeing the World<a href="#exteroceptive-sensors-seeing-the-world" class="hash-link" aria-label="Direct link to Exteroceptive Sensors: Seeing the World" title="Direct link to Exteroceptive Sensors: Seeing the World" translate="no">​</a></h3>
<p>These sensors gather information about the external environment.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="vision-cameras">Vision (Cameras)<a href="#vision-cameras" class="hash-link" aria-label="Direct link to Vision (Cameras)" title="Direct link to Vision (Cameras)" translate="no">​</a></h4>
<p>Cameras are the richest source of data for a robot, providing dense information about color, texture, and shape. They are passive, low-power, and inexpensive.</p>
<ul>
<li class=""><strong>Monocular Cameras:</strong> A single camera, like a human eye. It provides a 2D projection of the 3D world. Inferring depth is challenging but can be done with advanced AI models.</li>
<li class=""><strong>Stereo Cameras:</strong> Two cameras spaced a known distance apart. By comparing the two images (finding a disparity map), the robot can calculate depth through triangulation, mimicking human stereoscopic vision.</li>
<li class=""><strong>RGB-D (Depth) Cameras:</strong> These cameras directly provide a depth map alongside a standard color image. Common techniques include <em>Time-of-Flight (ToF)</em>, which measures the time it takes for light to bounce back to the sensor.</li>
</ul>
<p>The raw images from these cameras are processed by <strong>computer vision algorithms</strong>, which are now dominated by Deep Learning, specifically Convolutional Neural Networks (CNNs). Key tasks include:</p>
<ul>
<li class=""><strong>Object Detection:</strong> Identifying and drawing bounding boxes around objects (e.g., &quot;this is a cup&quot;).</li>
<li class=""><strong>Semantic Segmentation:</strong> Classifying every single pixel in an image (e.g., &quot;these pixels are &#x27;road&#x27;,&quot; &quot;these pixels are &#x27;sky&#x27;&quot;).</li>
<li class=""><strong>Pose Estimation:</strong> Determining an object&#x27;s precise 3D position and orientation relative to the camera.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="lidar-light-detection-and-ranging">LiDAR (Light Detection and Ranging)<a href="#lidar-light-detection-and-ranging" class="hash-link" aria-label="Direct link to LiDAR (Light Detection and Ranging)" title="Direct link to LiDAR (Light Detection and Ranging)" translate="no">​</a></h4>
<p>LiDAR sensors work by emitting rapid pulses of laser light and measuring the time it takes for the reflections to return.</p>
<ul>
<li class=""><strong>Output:</strong> This process generates a <strong>point cloud</strong>, which is a rich, 3D &quot;map&quot; of the surrounding environment.</li>
<li class=""><strong>Strengths:</strong> LiDAR is highly accurate for measuring distance and is unaffected by lighting conditions, making it excellent for mapping, localization, and detecting obstacles.</li>
<li class=""><strong>Weaknesses:</strong> It typically doesn&#x27;t provide color information and can have trouble with reflective or transparent surfaces.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="proprioceptive-sensors-understanding-self">Proprioceptive Sensors: Understanding Self<a href="#proprioceptive-sensors-understanding-self" class="hash-link" aria-label="Direct link to Proprioceptive Sensors: Understanding Self" title="Direct link to Proprioceptive Sensors: Understanding Self" translate="no">​</a></h3>
<p>These sensors provide information about the robot&#x27;s own state and movement.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="inertial-measurement-unit-imu">Inertial Measurement Unit (IMU)<a href="#inertial-measurement-unit-imu" class="hash-link" aria-label="Direct link to Inertial Measurement Unit (IMU)" title="Direct link to Inertial Measurement Unit (IMU)" translate="no">​</a></h4>
<p>The IMU is the core of the robot&#x27;s sense of balance, located near its center of mass.</p>
<ul>
<li class=""><strong>Components:</strong> It contains an <strong>accelerometer</strong> (measures linear acceleration) and a <strong>gyroscope</strong> (measures angular velocity).</li>
<li class=""><strong>Function:</strong> By integrating the data from the IMU, the robot can estimate its orientation (roll, pitch, yaw) and track its motion. It is absolutely critical for maintaining balance.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="joint-encoders">Joint Encoders<a href="#joint-encoders" class="hash-link" aria-label="Direct link to Joint Encoders" title="Direct link to Joint Encoders" translate="no">​</a></h4>
<p>These are the most fundamental proprioceptive sensors. An encoder is attached to every joint (motor) on the robot and provides a precise measurement of the joint&#x27;s angle. Without encoders, the robot would have no reliable knowledge of its own posture.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="force-torque-ft-sensors">Force-Torque (F/T) Sensors<a href="#force-torque-ft-sensors" class="hash-link" aria-label="Direct link to Force-Torque (F/T) Sensors" title="Direct link to Force-Torque (F/T) Sensors" translate="no">​</a></h4>
<p>Located in critical areas like the wrists and ankles, F/T sensors measure the forces and torques resulting from interaction with the environment. They allow the robot to feel when its foot is firmly on the ground or how much force it&#x27;s exerting while grasping an object. This is essential for compliant motion and safe physical interaction.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-power-of-fusion">The Power of Fusion<a href="#the-power-of-fusion" class="hash-link" aria-label="Direct link to The Power of Fusion" title="Direct link to The Power of Fusion" translate="no">​</a></h3>
<p>No single sensor is perfect. GPS can be inaccurate, IMUs drift over time, and camera-based estimates can be noisy. <strong>Sensor fusion</strong> is the process of intelligently combining data from multiple sensors to produce a state estimate that is more accurate, complete, and reliable than any individual sensor could provide.</p>
<p>The most common tool for this is the <strong>Kalman Filter</strong> (and its variants like the Extended Kalman Filter for non-linear systems). It&#x27;s a two-step process:</p>
<ol>
<li class=""><strong>Predict:</strong> The filter uses a motion model to predict the robot&#x27;s state at the next point in time.</li>
<li class=""><strong>Update:</strong> It then uses a new sensor measurement to correct and update this prediction.</li>
</ol>
<p>By fusing high-frequency data from an IMU with lower-frequency but more stable data from a camera or joint encoders, the robot can maintain a highly accurate and smooth estimate of its state.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="code-example-basic-obstacle-detection">Code Example: Basic Obstacle Detection<a href="#code-example-basic-obstacle-detection" class="hash-link" aria-label="Direct link to Code Example: Basic Obstacle Detection" title="Direct link to Code Example: Basic Obstacle Detection" translate="no">​</a></h3>
<p>Let&#x27;s simulate a basic perception task. Imagine we have a depth image from an RGB-D camera, represented as a 2D NumPy array where each value is the distance in meters. Our goal is to detect if there is an imminent obstacle directly in front of the robot.</p>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Python</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> numpy </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">check_for_imminent_obstacle</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">depth_image</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> danger_zone_m</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> obstacle_threshold_m</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">  Checks a central region of a depth image for obstacles.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">  Args:</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">      depth_image (np.array): 2D array representing the depth image.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">      danger_zone_m (float): How close an object must be to be an obstacle.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">      obstacle_threshold_m (float): Percentage of pixels in the danger zone</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">                                   that must be obstacles to trigger a warning.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">                                   </span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">  Returns:</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">      bool: True if an obstacle is detected, False otherwise.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">  &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  height</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> width </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> depth_image</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shape</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Define a central region of interest (e.g., middle 20% of the width)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  roi_start </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token builtin">int</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">width </span><span class="token operator" style="color:#393A34">//</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> width </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  roi_end </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token builtin">int</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">width </span><span class="token operator" style="color:#393A34">//</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> width </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  center_region </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> depth_image</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">:</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> roi_start</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">roi_end</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Find all pixels where the distance is less than our danger zone</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># and greater than zero (ignoring invalid depth readings)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  obstacle_pixels </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> center_region</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">center_region </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain"> danger_zone_m</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">center_region </span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Calculate the percentage of the region that is considered an obstacle</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  obstacle_percentage </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token builtin">len</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">obstacle_pixels</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">/</span><span class="token plain"> center_region</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">size</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;Obstacle percentage in center region: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">obstacle_percentage</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">:</span><span class="token string-interpolation interpolation format-spec">.2%</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> obstacle_percentage </span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> obstacle_threshold_m</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;WARNING: Imminent obstacle detected!&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">True</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">else</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Path ahead is clear.&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">False</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># --- Simulation ---</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Create a simulated 480x640 depth image, mostly clear (5 meters away)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">simulated_depth </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">full</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">480</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">640</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5.0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Add a close obstacle (0.5 meters away) in the center</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">simulated_depth</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">180</span><span class="token punctuation" style="color:#393A34">:</span><span class="token number" style="color:#36acaa">300</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">280</span><span class="token punctuation" style="color:#393A34">:</span><span class="token number" style="color:#36acaa">360</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.5</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># --- Run the check ---</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># An object is an obstacle if it&#x27;s closer than 1.0 meter</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># and if more than 30% of the center region is blocked.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">check_for_imminent_obstacle</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">simulated_depth</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> danger_zone_m</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1.0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> obstacle_threshold_m</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.3</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div></div></div></div></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/humanoid_robotics_textbook/ai-robot-brain/path-planning-reinforcement-learning/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Path Planning and Reinforcement Learning</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/humanoid_robotics_textbook/vla/chapter-4.1-voice-command-integration/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Voice Command Integration (OpenAI Whisper)</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#the-goal-from-raw-data-to-understanding" class="table-of-contents__link toc-highlight">The Goal: From Raw Data to Understanding</a><ul><li><a href="#exteroceptive-sensors-seeing-the-world" class="table-of-contents__link toc-highlight">Exteroceptive Sensors: Seeing the World</a></li><li><a href="#proprioceptive-sensors-understanding-self" class="table-of-contents__link toc-highlight">Proprioceptive Sensors: Understanding Self</a></li><li><a href="#the-power-of-fusion" class="table-of-contents__link toc-highlight">The Power of Fusion</a></li><li><a href="#code-example-basic-obstacle-detection" class="table-of-contents__link toc-highlight">Code Example: Basic Obstacle Detection</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Physical AI & Humanoid Robotics. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>